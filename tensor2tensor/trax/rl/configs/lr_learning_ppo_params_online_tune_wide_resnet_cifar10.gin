import tensor2tensor.trax.models
import tensor2tensor.trax.rl

# Parameters for ppo.training_loop:
# ==============================================================================
ppo.training_loop.n_optimizer_steps = 30
ppo.training_loop.boundary = 128
ppo.training_loop.max_timestep = 128
ppo.training_loop.max_timestep_eval = 128
ppo.training_loop.random_seed = 0
ppo.training_loop.gamma = 0.99
ppo.training_loop.lambda_ = 0.95
ppo.training_loop.c1 = 1.0
ppo.training_loop.c2 = 0.01
ppo.training_loop.eval_every_n = 10
ppo.training_loop.done_frac_for_policy_save = 0
ppo.training_loop.n_evals = 1
ppo.training_loop.len_history_for_policy = 1  # this needs to be bumped up.
ppo.training_loop.eval_temperatures = (1.0,)
ppo.training_loop.epochs = 1000
ppo.training_loop.policy_and_value_model = @trax.models.TransformerDecoder
